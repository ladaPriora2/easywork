{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9bad35b5",
   "metadata": {},
   "source": [
    "## 1. Загрузка данных\n",
    "### 1.1 Что делать, если файл с данными всего один"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4bb109e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# если .csv\n",
    "import pandas as pd\n",
    "df = pd.read_csv('название_файла.csv')\n",
    "\n",
    "# если json\n",
    "df = pd.read_json('название_файла.json')\n",
    "\n",
    "# если что-то на экселевском\n",
    "df = pd.read_excel('название_файла.xlsx')\n",
    "\n",
    "# если сказано считать данные из бд на sql\n",
    "# и есть ссылка на бд\n",
    "import sqlalchemy\n",
    "\n",
    "engine = sqlalchemy.create_engine(\n",
    "    \"postgresql://username:password@host:port/database_name\"\n",
    ")\n",
    "df = pd.read_sql(\"SELECT * FROM table_name\", engine)\n",
    "\n",
    "# если снова злосчастный geojson\n",
    "import geopandas as gpd\n",
    "gdf = gpd.read_file('название_геоджейсона.geojson')\n",
    "\n",
    "# если есть файл .pkl\n",
    "import pickle\n",
    "file_object = pickle.load('название_файла.pkl')\n",
    "\n",
    "# один pdf (?!)\n",
    "from pypdf import PdfReader\n",
    "\n",
    "reader = PdfReader(\"название_файла.pdf\")\n",
    "page = reader.pages[0] # номер страницы, отсчёт с 0\n",
    "text = page.extract_text() # извлечь текст"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac96331a",
   "metadata": {},
   "source": [
    "### 1.2 Что делать, если файлов много и они в одном формате"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc63087",
   "metadata": {},
   "outputs": [],
   "source": [
    "# используем параллельное чтение\n",
    "from multiprocessing import Pool\n",
    "from time import time\n",
    "import os\n",
    "\n",
    "# функция для считывания в отдельном процессе \n",
    "# отдельного файла\n",
    "def read_file(filename):\n",
    "    # сюда вставить действие по считыванию одного файла в необходимом формате\n",
    "    path_to_file = PATH_TO_DATA+filename\n",
    "    # result = ...\n",
    "    return result\n",
    "\n",
    "# количество процессов - берется в количестве ядер вашего компьютера\n",
    "NUM_PROCESS = os.cpu_count()\n",
    "\n",
    "with Pool(processes=NUM_PROCESS) as p:\n",
    "    data = p.map(read_file, files_list, chunksize=3)\n",
    "data = list(data)\n",
    "# дальше преобразовываете в DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "PATH_TO_DATA = 'data_dir'\n",
    "\n",
    "\n",
    "file_contents_list = [] # сюда записываем всё содержимое файлов\n",
    "for filename in os.listdir(PATH_TO_DATA):\n",
    "    print(filename)\n",
    "    with open(f'{PATH_TO_DATA}/{filename}', 'r', encoding='utf-8') as f:\n",
    "        dict_file_content = json.loads(f.read()) # считываем содержимое файла\n",
    "        # обращаемся к конкретному полю rewiews, по которому можем получить весь массив\n",
    "        for rewiew in dict_file_content['reviews']:\n",
    "            # каждую запись в этом массиве добавляем в список в виде датафрейма\n",
    "            file_contents_list.append(pd.DataFrame(rewiew, index=[0]))\n",
    "\n",
    "# склеиваем датафреймы в один\n",
    "data = pd.concat(file_contents_list, ignore_index=True)\n",
    "\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "from time import time\n",
    "import os\n",
    "\n",
    "# функция для считывания в отдельном процессе \n",
    "# отдельного файла\n",
    "def read_file(filename):\n",
    "    # сюда вставить действие по считыванию одного файла в необходимом формате\n",
    "    path_to_file = PATH_TO_DATA+filename\n",
    "    file_contents_list = list()\n",
    "    with open(f'{PATH_TO_DATA}/{filename}', 'r', encoding='utf-8') as f:\n",
    "        dict_file_content = json.loads(f.read())\n",
    "        for rewiew in dict_file_content['reviews']:\n",
    "            file_contents_list.append(pd.DataFrame(rewiew, index=[0]))\n",
    "    result = pd.concat(file_contents_list, ignore_index=True)\n",
    "    return result\n",
    "\n",
    "# количество процессов - берется в количестве ядер вашего компьютера\n",
    "NUM_PROCESS = os.cpu_count()\n",
    "files_list = os.listdir(PATH_TO_DATA)\n",
    "\n",
    "with Pool(processes=NUM_PROCESS) as p:\n",
    "    data = p.map(read_file, files_list, chunksize=3)\n",
    "data = pd.concat(list(data), ignore_index=True)\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0473d39d",
   "metadata": {},
   "source": [
    "## 2. Очистка и обработка данных\n",
    "### 2.1 Обработка пропусков, невалидных значений и выбросов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88c8b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# пропуски\n",
    "df.isnull().sum / len(df) * 100 # в процентном соотношении\n",
    "\n",
    "# можно визуализировать\n",
    "import seaborn as sns\n",
    "colours = ['#000099', '#ffff00'] \n",
    "sns.heatmap(df[cols].isnull(), cmap=sns.color_palette(colours))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d62206b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# иногда пропуски не отображаются, но в данных всё равно присутствуют невалидные значения\n",
    "# ваша задача -- их найти, способ определяется данными\n",
    "# если вы их нашли, заменить вы всегда можете\n",
    "df.replace('что-то', 'на что-то') # для всего датафрейма\n",
    "df['конкретный_столбец'].replace('что-то', 'на что-то') # для конкретного столбца"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760c8d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# атрибут считается невосстановимым и удаляется, если у него пропусков ~50-60%\n",
    "irretrievable_cols = list()\n",
    "threshhold = 60 # порог задаётся вами\n",
    "for column in data_all.columns:\n",
    "    if data_all[column].isnull().sum() / all_records * 100 > threshhold:\n",
    "        irretrievable_cols.append(column)\n",
    "print(f\"Невосстановимые признаки, у которых пропусков более 60%: {irretrievable_cols}\")\n",
    "data_all.drop(columns=irretrievable_cols, inplace=True) # Настя, вот здесь удаление, если что"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4953e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# очистку выбросов смотрите в лекции 4.\n",
    "# выбросы обрабатываются только у непрерывных (континуальных) атрибутов,\n",
    "# то есть у категориальных не нужно ничего удалять!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c702f5e9",
   "metadata": {},
   "source": [
    "### 2.2 Кодирование категориальных переменных\n",
    "Если все значения уникальные, они неделимы, то есть их нельзя разбить на некоторые составляющие -- кодируем одним из способов в 4-й лекции. Если они делятся, то есть они представлены в виде каких-нибудь строк, в которых есть несколько значимых элементов, или содержатся перечисления -- необходимо значения распарсить и только потом закодировать одним из способов в лекции 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb4830a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>room_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3+1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1+2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0+0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4+ 5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  room_count\n",
       "0        3+1\n",
       "1        1+2\n",
       "2        0+0\n",
       "3         + \n",
       "4       4+ 5"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# например, у вас есть столбец, в котором ячейки содержат наборы каких-то категорий\n",
    "# нужно сначала найти все уникальные значения для этого столбца, а затем закодировать ohe\n",
    "# смотрите лекцию 11\n",
    "\n",
    "# если у вас столбец содержит строки, в которых содержатся несколько уникальных значений\n",
    "# их нужно разбить и вытянуть эти значения по разным столбцам\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({\n",
    "    'room_count': ['3+1', '1+2', '0+0', '+ ', '4+ 5']\n",
    "})\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f964d3",
   "metadata": {},
   "source": [
    "В Турции количество комнат в объекте недвижимости обозначается двумя числами: первое - количество жилых комнат, второе - количество спален. Оба числа важны, можно выделить два новых атрибута."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2fe17a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     [3, 1]\n",
       "1     [1, 2]\n",
       "2     [0, 0]\n",
       "3      [,  ]\n",
       "4    [4,  5]\n",
       "Name: room_count, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# сначала разобьем строки по символу-разделителю\n",
    "df['room_count'].str.split('+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0640bee9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     [3, 1]\n",
       "1     [1, 2]\n",
       "2     [0, 0]\n",
       "3      [,  ]\n",
       "4    [4,  5]\n",
       "Name: room_count, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# на выходе получились списки, можно обратиться к элементам по индексам\n",
    "df['room_count'].apply(lambda x: x.split('+'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f04ae409",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>room_count</th>\n",
       "      <th>living_room</th>\n",
       "      <th>bedrooms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3+1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1+2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0+0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>+</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4+ 5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  room_count  living_room  bedrooms\n",
       "0        3+1            3         1\n",
       "1        1+2            1         2\n",
       "2        0+0            0         0\n",
       "3         +             0         0\n",
       "4       4+ 5            4         5"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['living_room'] = df['room_count'].apply(lambda x: int(x.split('+')[0]) \\\n",
    "                                           if x.split('+')[0] not in ['', ' '] else 0)\n",
    "df['bedrooms'] = df['room_count'].apply(lambda x: int(x.split('+')[1]) \\\n",
    "                                        if x.split('+')[1] not in ['', ' '] else 0)\n",
    "\n",
    "# теперь нужно удалить старый признак и разобраться с нулями в двух новых\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07db1e5e",
   "metadata": {},
   "source": [
    "## 3. Выявление важных признаков и их визуализация\n",
    "### 3.1 Корреляция\n",
    "**Корреляция** - величина, которая показывает, что два явления происходят совместно. Как вычислять корреляцию - смотреть в лекции 11_2. \n",
    "\n",
    "Положительная корреляция говорит о том, что два события происходят совместно и связь между ними обычно прямая пропорциональная, отрицательная корреляция - связь обратно пропорциональная (одна переменная увеличивается, другая уменьшается)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca51a3d",
   "metadata": {},
   "source": [
    "Если целевая переменная (то, что нужно предсказывать) коррелирует с другими признаками (высокая корреляция -- это выше 0.75 без учета знака минуса), то это хорошо, признаки влияют на целевую переменную, можно применить линейные модели (SGDClassifier, LogisticRegression). \n",
    "\n",
    "Если высокой корреляции нет, используем нелинейные модели (дерево, лес, бустинг на деревьях)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243151c5",
   "metadata": {},
   "source": [
    "Если признаки имеют между собой высокую корреляцию, то это плохо, в данных есть лишние зависимости, от одного из двух в паре признаков необходимо избавиться."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696a61db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# в общих чертах \n",
    "corr = df.corr()\n",
    "sns.heatmap(corr, annot=True, fmt='.1g', vmin=-1, vmax=1);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b627b0d",
   "metadata": {},
   "source": [
    "### 3.2 Показатель взаимной информации\n",
    "Существует также специальный показатель взаимной информации, который способен отражать нелинейные связи (в отличие от корреляции). Кратко, как его запрограммировать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca9ec8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "# для регрессии используйте mutual_info_regression\n",
    "\n",
    "def make_mi_scores(X, y, discrete_features):\n",
    "    mi_scores = mutual_info_classif(X, y, discrete_features=discrete_features)\n",
    "    mi_scores = pd.Series(mi_scores, name=\"MI Scores\", index=X.columns)\n",
    "    mi_scores = mi_scores.sort_values(ascending=False)\n",
    "    return mi_scores\n",
    "\n",
    "def plot_mi_scores(scores):\n",
    "    scores = scores.sort_values(ascending=True)\n",
    "    width = np.arange(len(scores))\n",
    "    ticks = list(scores.index)\n",
    "    plt.barh(width, scores, color='purple')\n",
    "    plt.yticks(width, ticks)\n",
    "    plt.title(\"Показатели взаимной информации\")\n",
    "\n",
    "X_int = X.select_dtypes(include=['int'])\n",
    "discrete_features = X_int.dtypes == 'int'\n",
    "mi_scores = make_mi_scores(X_int, y, discrete_features)\n",
    "\n",
    "plt.figure(dpi=100, figsize=(8, 5))\n",
    "# отобразим только 15 наиболее значимых признаков\n",
    "plot_mi_scores(mi_scores[:15])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84323355",
   "metadata": {},
   "source": [
    "### 3.3 Визуалиазация различий конкретного признака между классами\n",
    "Иногда корреляция и взаимная информация не бывают так наглядны, как гистограммы распределений признака по классам целевой переменной (если мы говорим о задаче классификации). Можно попробовать код из лекции 11_1, где приводятся гистограммы распределений значений индекса опасности для уровней опасности. Или код из лекции 13, где иллюстрируется отличие длины СМС со спамом от длины СМС без спама."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c5e44fd",
   "metadata": {},
   "source": [
    "## 4. Конструирование новых признаков\n",
    "Иногда требуется (даже если это явно не сказано) создать целевую переменную. Для этого нужно создать атрибут по приведённому в задании алгоритму, а затем:\n",
    "- если задача классификации, то необходимо все значения нового признака собрать в некоторые категории, для этого лучше всего использовать алгоритм кластеризации (так вы сохраните зависимости внутри данных, если кластеризуете только новый получившийся атрибут, либо сможете выстроить значения внутри этого атрибута по некоторой шкале);\n",
    "- если у вас задача регрессии, то ничего дальше делать не нужно - у вас уже готова целевая переменная."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e8dab3",
   "metadata": {},
   "source": [
    "Пример кластеризации можно найти в лекции 11_1, где разбивается индекс опасности на произвольное число классов опасности. \n",
    "\n",
    "Здесь приведён общий шаблон для построения графика локтя для алгоритма кластеризации KMeans. Выбираем то количество кластеров, которое находится примерно в изгибе получившегося \"локтя\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9291c377",
   "metadata": {},
   "outputs": [],
   "source": [
    "# если количество классов в задаче классификации не указано, оно произвольно, то нужно подобрать \n",
    "# его самостоятельно по методу локтя\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "X_scaled = StandardScaler().fit_transform(df[['тот_признак_который_нужно_разбить_на_классы']])\n",
    "inertia = [] \n",
    "max_clusters = 10  # это число может быть произвольным\n",
    "for i in range(2, max_clusters + 1):\n",
    "    kmeans = KMeans(n_clusters=i, random_state=2023)\n",
    "    kmeans.fit(X_scaled)\n",
    "    inertia.append(kmeans.inertia_)\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(range(2, max_clusters + 1), inertia, marker='o', linestyle='--', color='purple')\n",
    "plt.title('Метод локтя')\n",
    "plt.xlabel('Количество кластеров(K)')\n",
    "plt.ylabel('WCSS')\n",
    "plt.grid()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92796589",
   "metadata": {},
   "source": [
    "Если в задаче ЯВНО СКАЗАНО, СКОЛЬКО КЛАССОВ должно быть, тогда сразу используем этот кусок кода, НЕ ИСПОЛЬЗУЕМ МЕТОД ЛОКТЯ, код выше НЕ ТРОГАЕМ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2bdc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# допустим, три класса опасности \n",
    "num_classes = 3\n",
    "kmeans = KMeans(n_clusters=num_classes, random_state=0)\n",
    "clusters = kmeans.fit_predict(X_scaled)\n",
    "all_regions['целевая_переменная'] = clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7faea2",
   "metadata": {},
   "source": [
    "## 5. Разбиение данных на тренировочный и проверочный наборы\n",
    "Здесь всё достаточно просто, НО:\n",
    "- строим гистограмму целевой переменной и даём комментарии, сбалансированы/не сбалансированы классы в целевой переменной, если это задача классификации;\n",
    "- если задача регрессии, то делаем комментарии относительно формы распределения, если знаете что-то про это (писать комментарии в духе \"ну, признак распределён красиво, нормально\" запрещается, вы не знаете, что такое нормальное распределение).\n",
    "\n",
    "А дальше train_test_split, не забываем про параметр stratify=y, который позволит разбить данные в одинаковом соотношении классов как в train, так и в test."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66a8aad",
   "metadata": {},
   "source": [
    "## 6. Обучение\n",
    "Тоже до неприличия просто. \n",
    "### Делай раз: метрики и оценка модели\n",
    "Согласно поговорке, готовь сани летом, а функции оценки модели - первым делом на этом этапе.\n",
    "\n",
    "Ещё раз:\n",
    "- если у вас задача классификации:\n",
    "    - если это задача бинарной классификации (всего два класса):\n",
    "        - если просят оценить вероятности чего-либо (принадлежности объекта кому-либо, вероятность ухода человека из компании и т.д.):\n",
    "            - используем метрику ROC_AUC и чертим кривую ROC\n",
    "        - если не просят оценивать вероятности, ничего об этом не сказано, в данных есть дисбаланс:\n",
    "            - используем precision_score, recall_score и f1_score (точность, полнота и f-мера)\n",
    "    - если это задача множественной классификации (больше двух классов):\n",
    "        - используем precision_score, recall_score и f1_score (точность, полнота и f-мера)\n",
    "- если задача регрессии:\n",
    "    используем все метрики в приведённой ниже функции quality_regression_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "395ef7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция для ROC_AUC и ROC-кривой\n",
    "# функция принимает на вход вероятности, в practice/anomaly_2 посмотрите, как она используется\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "\n",
    "def plot_roc_curve(probas, y_true):\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, probas) \n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.0])\n",
    "    plt.plot([0, 1], [0, 1], color=\"navy\", lw=2, linestyle=\"--\")\n",
    "    plt.plot(fpr, tpr, color=\"darkorange\");\n",
    "    plt.title(f\"ROC_AUC: {round(roc_auc_score(y_true, probas), 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a6e779",
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция для оценки точности, полноты, f-меры\n",
    "# функция также отрисовывает матрицу неточностей, что позволит увидеть, где модель ошиблась\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# соберём все метрики в одну функцию\n",
    "def quality_report(prediction, actual):\n",
    "    print(\"Accuracy: {:.3f}\\nPrecision: {:.3f}\\nRecall: {:.3f}\\nf1_score: {:.3f}\".format(\n",
    "        accuracy_score(prediction, actual),\n",
    "        precision_score(prediction, actual, average='weighted'),\n",
    "        recall_score(prediction, actual, average='weighted', zero_division=1),\n",
    "        f1_score(prediction, actual, average='weighted')\n",
    "    ))\n",
    "    \n",
    "    cnf_matrix = confusion_matrix(actual, prediction)\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    \n",
    "    # обычная матрица неточностей\n",
    "    plt.subplot(2, 2, 1, \n",
    "                title='Матрица неточностей',\n",
    "                ylabel='Истинные метки',\n",
    "                xlabel='Прогнозы')\n",
    "    sns.heatmap(cnf_matrix, annot=True)\n",
    "    \n",
    "    # нормализованная матрица неточностей\n",
    "    cnf_matrix = cnf_matrix / cnf_matrix.sum(axis=1, keepdims=True)\n",
    "    plt.subplot(2, 2, 2, \n",
    "                title='Матрица неточностей нормализованная',\n",
    "                ylabel='Истинные метки',\n",
    "                xlabel='Прогнозы')\n",
    "    sns.heatmap(cnf_matrix, fmt='.1g', cmap=plt.cm.gray)\n",
    "\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0165f6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция с метриками для задачи регрессии\n",
    "from sklearn import metrics\n",
    "def quality_regression_report(y_test,y_pred):\n",
    "    print('MAE:', metrics.mean_absolute_error(np.exp(y_test), np.exp(y_pred)))\n",
    "    print('RMSE:', np.sqrt(metrics.mean_squared_error(np.exp(y_test), np.exp(y_pred))))\n",
    "    print('R2:',  metrics.r2_score(y_test, y_pred))\n",
    "    print('MAPE:', mean_absolute_percentage_error(y_test, y_pred))\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963a1149",
   "metadata": {},
   "source": [
    "### Делай два: непосредственно обучение модели\n",
    "1. Достаём модель:\n",
    "\n",
    "    from sklearn.{подставьте_сюда_название_пакета} import {подставьте_сюда_название_класса_модели}\n",
    "    model = {подставьте_сюда_название_класса_модели}(здесь=должны, быть=параметры)\n",
    "    \n",
    "2. Обучаем:\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "3. Получаем прогнозы:\n",
    "    - если просят вероятности:\n",
    "        pred_probs = model.predict_proba(X_test)\n",
    "    - если не просят вероятности:\n",
    "        preds = model.predict(X_test)\n",
    "\n",
    "4. Оцениваем модель:\n",
    "    - если задача бинарной классификации и метрика ROC_AUC:\n",
    "        - plot_roc_curve(pred_probs[:, 1], y_test)\n",
    "    - если задача бинарной или небинарной классификации и ничего не сказано про вероятности, то:\n",
    "        - quality_report(preds, y_test)\n",
    "        \n",
    "    - если задача регресси:\n",
    "        - quality_regression_report(preds, y_test)\n",
    "        \n",
    "       \n",
    "И ТАК ТРИ РАЗА. ЗАМЕРЯТЬ КАЧЕСТВО НУЖНО КАК НА ТРЕЙНЕ, ТАК И НА ТЕСТЕ, ЕСЛИ СИЛЬНО РАСХОДЯТСЯ ПОКАЗАТЕЛИ - ПОЗДРАВЛЯЮ, У ВАС ПЕРЕОБУЧЕНИЕ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799f7fbb",
   "metadata": {},
   "source": [
    "### Делай три: оптимизируем модель\n",
    "Есть несколько способов оптимизировать модель. Один из них - это решетчатый поиск (GridSearchCV).\n",
    "\n",
    "Что здесь нужно знать и учитывать:\n",
    "- параметры модели можно нагуглить в документации sklearn, не выбирайте очень много, иначе есть риск, что ваши дети будут сдавать демоэкзамен к тому времени, когда GridSearchCV закончит поиск;\n",
    "- обязательно указывайте в параметре scoring, какую метрику необходимо оптимизировать, иначе по умолчанию будет поиск параметров для лучшей accuracy, а у вас в данных дисбаланс - такое себе;\n",
    "- не используйте решетчатый поиск на случайных лесах и градиентом бустинге (вообще на всех ансамблях)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837a9f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# это пример для логистической регрессии\n",
    "# сетка параметров модели, которые необходимо подобрать\n",
    "model_params = {\n",
    "    'penalty' : ['l1', 'l2', 'elasticnet'],\n",
    "    'C' : [0.1, 1, 1.3, 1.4, 1.5, 2, 5, 10],\n",
    "    'class_weight' : [None, 'balanced']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=LogisticRegression(solver='liblinear', random_state=2023),\n",
    "                          param_grid=model_params, scoring='roc_auc', cv=5, n_jobs=-1,\n",
    "                          return_train_score=True)\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(f\"Лучшие параметры: {grid_search.best_params_}\\nЛучший результат: {grid_search.best_score_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f8ec98",
   "metadata": {},
   "source": [
    "Иногда просят построить кривые валидации и обучения. ИХ МОЖНО ИСПОЛЬЗОВАТЬ ДЛЯ АНСАМБЛЕЙ ДЛЯ ПОИСКА ПАРАМЕТРОВ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a0beaf",
   "metadata": {},
   "source": [
    "**Кривая валидации** -- график влияния одного гиперпараметра на оценку обучения и оценку валидации модели.\n",
    "\n",
    "**Кривая обучения** -- график, который показывает оценку валидации и обучения модели для различного количества обучающих выборок. Это инструмент, позволяющий узнать, насколько мы выигрываем от добавления дополнительных обучающих данных и страдает ли модель больше от ошибки дисперсии или ошибки смещения. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a552ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_validation_curve(model, X, y, \n",
    "                          param_name, param_range):\n",
    "    from sklearn.model_selection import validation_curve\n",
    "    train_scores, valid_scores = validation_curve(model, X, y, \n",
    "                                                  param_name=param_name, \n",
    "                                                  param_range=param_range,\n",
    "                                                  scoring='roc_auc', n_jobs=-1)\n",
    "    \n",
    "    train_mean = np.mean(train_scores, axis=1)\n",
    "    train_std = np.std(train_scores, axis=1)\n",
    "    valid_mean = np.mean(valid_scores, axis=1)\n",
    "    valid_std = np.std(valid_scores, axis=1)\n",
    "    \n",
    "    plt.plot(param_range, train_mean, label=\"Training Score\", color=\"blue\")\n",
    "    plt.plot(param_range, valid_mean, label=\"Validation Score\", color=\"red\")\n",
    "\n",
    "    plt.fill_between(param_range, train_mean - train_std, train_mean + train_std, color=\"lightblue\")\n",
    "    plt.fill_between(param_range, valid_mean - valid_std, valid_mean + valid_std, color=\"pink\")\n",
    "\n",
    "    plt.xlabel(param_name)\n",
    "    plt.ylabel(\"Качество классификации\")\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.title(\"Кривая валидации\");\n",
    "    \n",
    "def plot_learning_curve(model, X, y, train_sizes):\n",
    "    from sklearn.model_selection import learning_curve\n",
    "    train_sizes, train_scores, valid_scores = learning_curve(model, X, y, \n",
    "                                                             train_sizes=train_sizes, \n",
    "                                                             scoring='roc_auc',\n",
    "                                                             n_jobs=-1)\n",
    "\n",
    "    train_mean = np.mean(train_scores, axis=1)\n",
    "    train_std = np.std(train_scores, axis=1)\n",
    "    valid_mean = np.mean(valid_scores, axis=1)\n",
    "    valid_std = np.std(valid_scores, axis=1)\n",
    "\n",
    "    plt.plot(train_sizes, train_mean, label=\"Training Score\", color=\"blue\")\n",
    "    plt.plot(train_sizes, valid_mean, label=\"Validation Score\", color=\"red\")\n",
    "\n",
    "    plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, color=\"lightblue\")\n",
    "    plt.fill_between(train_sizes, valid_mean - valid_std, valid_mean + valid_std, color=\"pink\")\n",
    "\n",
    "    plt.xlabel(\"Объем выборки\")\n",
    "    plt.ylabel(\"Качество классификации\")\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.title(\"Кривая обучения\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd31aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# здесь меняете модель, параметр и значения параметра\n",
    "plot_validation_curve(LogisticRegression(solver='liblinear', penalty='l2', random_state=2023),\n",
    "                    X_train, y_train, 'C', model_params['C'])\n",
    "\n",
    "# здесь меняете только модель\n",
    "plot_learning_curve(LogisticRegression(solver='liblinear', C=2, \n",
    "                                       penalty='l2', random_state=2023),\n",
    "                    X_train, y_train, \n",
    "                    [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4067459",
   "metadata": {},
   "source": [
    "## 7. Преобразование/трансформация данных\n",
    "Если в задании рядом находятся требование преобразовать данные и слова 'feature engineering', то это однозначно про снижение размерностей (мы его делали через PCA). Описание применения есть в лекции 11_2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8507d5e0",
   "metadata": {},
   "source": [
    "## 8. Общие советы\n",
    "1. Делаем всё максимально возможное, потому что не знаем, за что нам дадут балл, а за что не дадут.\n",
    "2. Сохраняем результаты работы в конце каждого модуля под теми именами, которые указаны в задании.\n",
    "3. Пишем комментарии везде. Если хотим сдать хотя бы на \"3\". Не хотим - не пишем, на экзамен вообще не приходим.\n",
    "4. В конце каждого отчёта по модулю необходимо сделать небольшое саммари - в паре слов подвести итог проделанной работы."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
